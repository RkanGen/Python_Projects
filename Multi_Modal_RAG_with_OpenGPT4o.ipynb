{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMYDYpyqbW4Pw/JKNVtv8P0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RkanGen/Python_Projects/blob/main/Multi_Modal_RAG_with_OpenGPT4o.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5nNNQncl4m0",
        "outputId": "c30a56ff-ac2a-4900-cdf5-00deb85b1dfd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "# Import modules from other files\n",
        "from chatbot import chatbot, model_inference, BOT_AVATAR, EXAMPLES, model_selector, decoding_strategy, temperature, max_new_tokens, repetition_penalty, top_p\n",
        "from live_chat import videochat"
      ],
      "metadata": {
        "id": "8nreq_a5mQat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Gradio theme\n",
        "theme = gr.themes.Soft(\n",
        "    primary_hue=\"blue\",\n",
        "    secondary_hue=\"orange\",\n",
        "    neutral_hue=\"gray\",\n",
        "    font=[gr.themes.GoogleFont('Libre Franklin'), gr.themes.GoogleFont('Public Sans'), 'system-ui', 'sans-serif']\n",
        ").set(\n",
        "    body_background_fill_dark=\"#111111\",\n",
        "    block_background_fill_dark=\"#111111\",\n",
        "    block_border_width=\"1px\",\n",
        "    block_title_background_fill_dark=\"#1e1c26\",\n",
        "    input_background_fill_dark=\"#292733\",\n",
        "    button_secondary_background_fill_dark=\"#24212b\",\n",
        "    border_color_primary_dark=\"#343140\",\n",
        "    background_fill_secondary_dark=\"#111111\",\n",
        "    color_accent_soft_dark=\"transparent\"\n",
        ")"
      ],
      "metadata": {
        "id": "B4lVgZ_-mQXj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import edge_tts\n",
        "import asyncio\n",
        "import tempfile\n",
        "import numpy as np\n",
        "import soxr\n",
        "from pydub import AudioSegment\n",
        "import torch\n",
        "import sentencepiece as spm\n",
        "import onnxruntime as ort\n",
        "from huggingface_hub import hf_hub_download, InferenceClient\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import urllib\n",
        "import random"
      ],
      "metadata": {
        "id": "b4XvzLKLmQUe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of user agents to choose from for requests\n",
        "_useragent_list = [\n",
        "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:66.0) Gecko/20100101 Firefox/66.0',\n",
        "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/111.0.0.0 Safari/537.36',\n",
        "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/111.0.0.0 Safari/537.36',\n",
        "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/109.0.0.0 Safari/537.36',\n",
        "    'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/111.0.0.0 Safari/537.36',\n",
        "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/111.0.0.0 Safari/537.36 Edg/111.0.1661.62',\n",
        "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/111.0'\n",
        "]"
      ],
      "metadata": {
        "id": "0Logb9wImQPw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_text_from_webpage(html_content):\n",
        "    \"\"\"Extracts visible text from HTML content using BeautifulSoup.\"\"\"\n",
        "    soup = BeautifulSoup(html_content, \"html.parser\")\n",
        "    # Remove unwanted tags\n",
        "    for tag in soup([\"script\", \"style\", \"header\", \"footer\", \"nav\"]):\n",
        "        tag.extract()\n",
        "    # Get the remaining visible text\n",
        "    visible_text = soup.get_text(strip=True)\n",
        "    return visible_text"
      ],
      "metadata": {
        "id": "JNeHASCwmQL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def search(term, num_results=1, lang=\"en\", advanced=True, sleep_interval=0, timeout=5, safe=\"active\", ssl_verify=None):\n",
        "    \"\"\"Performs a Google search and returns the results.\"\"\"\n",
        "    escaped_term = urllib.parse.quote_plus(term)\n",
        "    start = 0\n",
        "    all_results = []\n",
        "\n",
        "    # Fetch results in batches\n",
        "    while start < num_results:\n",
        "        resp = requests.get(\n",
        "            url=\"https://www.google.com/search\",\n",
        "            headers={\"User-Agent\": get_useragent()}, # Set random user agent\n",
        "            params={\n",
        "                \"q\": term,\n",
        "                \"num\": num_results - start, # Number of results to fetch in this batch\n",
        "                \"hl\": lang,\n",
        "                \"start\": start,\n",
        "                \"safe\": safe,\n",
        "            },\n",
        "            timeout=timeout,\n",
        "            verify=ssl_verify,\n",
        "        )\n",
        "        resp.raise_for_status() # Raise an exception if request fails\n",
        "\n",
        "        soup = BeautifulSoup(resp.text, \"html.parser\")\n",
        "        result_block = soup.find_all(\"div\", attrs={\"class\": \"g\"})\n",
        "\n",
        "        # If no results, continue to the next batch\n",
        "        if not result_block:\n",
        "            start += 1\n",
        "            continue\n",
        "\n",
        "        # Extract link and text from each result\n",
        "        for result in result_block:\n",
        "            link = result.find(\"a\", href=True)\n",
        "            if link:\n",
        "                link = link[\"href\"]\n",
        "                try:\n",
        "                    # Fetch webpage content\n",
        "                    webpage = requests.get(link, headers={\"User-Agent\": get_useragent()})\n",
        "                    webpage.raise_for_status()\n",
        "                    # Extract visible text from webpage\n",
        "                    visible_text = extract_text_from_webpage(webpage.text)\n",
        "                    all_results.append({\"link\": link, \"text\": visible_text})\n",
        "                except requests.exceptions.RequestException as e:\n",
        "                    # Handle errors fetching or processing webpage\n",
        "                    print(f\"Error fetching or processing {link}: {e}\")\n",
        "                    all_results.append({\"link\": link, \"text\": None})\n",
        "            else:\n",
        "                all_results.append({\"link\": None, \"text\": None})\n",
        "\n",
        "        start += len(result_block) # Update starting index for next batch\n",
        "\n",
        "    return all_results"
      ],
      "metadata": {
        "id": "Z9RcQi7jmP_b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Speech Recognition Model Configuration\n",
        "model_name = \"neongeckocom/stt_en_citrinet_512_gamma_0_25\"\n",
        "sample_rate = 16000\n",
        "\n",
        "# Download preprocessor, encoder and tokenizer\n",
        "preprocessor = torch.jit.load(hf_hub_download(model_name, \"preprocessor.ts\", subfolder=\"onnx\"))\n",
        "encoder = ort.InferenceSession(hf_hub_download(model_name, \"model.onnx\", subfolder=\"onnx\"))\n",
        "tokenizer = spm.SentencePieceProcessor(hf_hub_download(model_name, \"tokenizer.spm\", subfolder=\"onnx\"))\n",
        "\n",
        "# Mistral Model Configuration\n",
        "client1 = InferenceClient(\"mistralai/Mixtral-8x7B-Instruct-v0.1\")\n",
        "system_instructions1 = \"<s>[SYSTEM] Answer as Real OpenGPT 4o, Made by 'KingNish', Keep conversation very short, clear, friendly and concise. The text provided is a request for a specific type of response from you, the virtual assistant. The request asks you to provide friendly responses. The expectation is that I will avoid introductions and start answering the query directly, elaborating on all aspects of the request. As an AI-powered assistant, your task is to generate responses that appear as if they are created by the user and not an AI-powered assistant. [USER]\""
      ],
      "metadata": {
        "id": "KJUNEmeVqTGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def resample(audio_fp32, sr):\n",
        "    return soxr.resample(audio_fp32, sr, sample_rate)\n",
        "\n",
        "def to_float32(audio_buffer):\n",
        "    return np.divide(audio_buffer, np.iinfo(audio_buffer.dtype).max, dtype=np.float32)\n",
        "\n",
        "def transcribe(audio_path):\n",
        "    audio_file = AudioSegment.from_file(audio_path)\n",
        "    sr = audio_file.frame_rate\n",
        "    audio_buffer = np.array(audio_file.get_array_of_samples())\n",
        "\n",
        "    audio_fp32 = to_float32(audio_buffer)\n",
        "    audio_16k = resample(audio_fp32, sr)\n",
        "\n",
        "    input_signal = torch.tensor(audio_16k).unsqueeze(0)\n",
        "    length = torch.tensor(len(audio_16k)).unsqueeze(0)\n",
        "    processed_signal, _ = preprocessor.forward(input_signal=input_signal, length=length)\n",
        "\n",
        "    logits = encoder.run(None, {'audio_signal': processed_signal.numpy(), 'length': length.numpy()})[0][0]\n",
        "\n",
        "    blank_id = tokenizer.vocab_size()\n",
        "    decoded_prediction = [p for p in logits.argmax(axis=1).tolist() if p != blank_id]\n",
        "    text = tokenizer.decode_ids(decoded_prediction)\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "id": "_6Gg9JHhqWpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model(text, web_search):\n",
        "    if web_search is True:\n",
        "        \"\"\"Performs a web search, feeds the results to a language model, and returns the answer.\"\"\"\n",
        "        web_results = search(text)\n",
        "        web2 = ' '.join([f\"Link: {res['link']}\\nText: {res['text']}\\n\\n\" for res in web_results])\n",
        "        formatted_prompt = system_instructions1 + text + \"[WEB]\" + str(web2) + \"[OpenGPT 4o]\"\n",
        "        stream = client1.text_generation(formatted_prompt, max_new_tokens=512, stream=True, details=True, return_full_text=False)\n",
        "        return \"\".join([response.token.text for response in stream if response.token.text != \"</s>\"])\n",
        "    else:\n",
        "        formatted_prompt = system_instructions1 + text + \"[OpenGPT 4o]\"\n",
        "        stream = client1.text_generation(formatted_prompt, max_new_tokens=512, stream=True, details=True, return_full_text=False)\n",
        "        return \"\".join([response.token.text for response in stream if response.token.text != \"</s>\"])"
      ],
      "metadata": {
        "id": "olhADdn4qWkp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "async def respond(audio, web_search):\n",
        "    user = transcribe(audio)\n",
        "    reply = model(user, web_search)\n",
        "    communicate = edge_tts.Communicate(reply)\n",
        "    with tempfile.NamedTemporaryFile(delete=False, suffix=\".wav\") as tmp_file:\n",
        "        tmp_path = tmp_file.name\n",
        "        await communicate.save(tmp_path)\n",
        "    return tmp_path"
      ],
      "metadata": {
        "id": "n9AXx003qWge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with gr.Blocks() as voice:\n",
        "    gr.Markdown(\"## Temproraly Not Working (Update in Progress)\")\n",
        "    with gr.Row():\n",
        "        web_search = gr.Checkbox(label=\"Web Search\", value=False)\n",
        "        input = gr.Audio(label=\"User Input\", sources=\"microphone\", type=\"filepath\")\n",
        "        output = gr.Audio(label=\"AI\", autoplay=True)\n",
        "        gr.Interface(fn=respond, inputs=[input, web_search], outputs=[output], live=True)"
      ],
      "metadata": {
        "id": "yoqq0w-fqWUP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Gradio blocks for different functionalities\n",
        "\n",
        "# Chat interface block\n",
        "with gr.Blocks(\n",
        "        fill_height=True,\n",
        "        css=\"\"\".gradio-container .avatar-container {height: 40px width: 40px !important;} #duplicate-button {margin: auto; color: white; background: #f1a139; border-radius: 100vh; margin-top: 2px; margin-bottom: 2px;}\"\"\",\n",
        ") as chat:\n",
        "    gr.Markdown(\"### Image Chat, Image Generation and Normal Chat\")\n",
        "    with gr.Row(elem_id=\"model_selector_row\"):\n",
        "        # model_selector defined in chatbot.py\n",
        "        pass\n",
        "    # decoding_strategy, temperature, top_p defined in chatbot.py\n",
        "    decoding_strategy.change(\n",
        "        fn=lambda selection: gr.Slider(\n",
        "            visible=(\n",
        "                    selection\n",
        "                    in [\n",
        "                        \"contrastive_sampling\",\n",
        "                        \"beam_sampling\",\n",
        "                        \"Top P Sampling\",\n",
        "                        \"sampling_top_k\",\n",
        "                    ]\n",
        "            )\n",
        "        ),\n",
        "        inputs=decoding_strategy,\n",
        "        outputs=temperature,\n",
        "    )\n",
        "    decoding_strategy.change(\n",
        "        fn=lambda selection: gr.Slider(visible=(selection in [\"Top P Sampling\"])),\n",
        "        inputs=decoding_strategy,\n",
        "        outputs=top_p,\n",
        "    )\n",
        "    gr.ChatInterface(\n",
        "        fn=model_inference,\n",
        "        chatbot=chatbot,\n",
        "        examples=EXAMPLES,\n",
        "        multimodal=True,\n",
        "        cache_examples=False,\n",
        "        additional_inputs=[\n",
        "            model_selector,\n",
        "            decoding_strategy,\n",
        "            temperature,\n",
        "            max_new_tokens,\n",
        "            repetition_penalty,\n",
        "            top_p,\n",
        "            gr.Checkbox(label=\"Web Search\", value=True),\n",
        "        ],\n",
        "    )"
      ],
      "metadata": {
        "id": "xs7c1JaLqw2D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Live chat block\n",
        "with gr.Blocks() as livechat:\n",
        "    gr.Interface(\n",
        "        fn=videochat,\n",
        "        inputs=[gr.Image(type=\"pil\",sources=\"webcam\", label=\"Upload Image\"), gr.Textbox(label=\"Prompt\", value=\"what he is doing\")],\n",
        "        outputs=gr.Textbox(label=\"Answer\")\n",
        "    )\n",
        "\n",
        "# Other blocks (instant, dalle, playground, image, instant2, video)\n",
        "with gr.Blocks() as instant:\n",
        "    gr.HTML(\"<iframe src='https://kingnish-sdxl-flash.hf.space' width='100%' height='2000px' style='border-radius: 8px;'></iframe>\")"
      ],
      "metadata": {
        "id": "kX-9r8CMrBs-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with gr.Blocks() as dalle:\n",
        "    gr.HTML(\"<iframe src='https://kingnish-image-gen-pro.hf.space' width='100%' height='2000px' style='border-radius: 8px;'></iframe>\")\n",
        "\n",
        "with gr.Blocks() as playground:\n",
        "    gr.HTML(\"<iframe src='https://fluently-fluently-playground.hf.space' width='100%' height='2000px' style='border-radius: 8px;'></iframe>\")\n",
        "\n",
        "with gr.Blocks() as image:\n",
        "    gr.Markdown(\"\"\"### More models are coming\"\"\")\n",
        "    gr.TabbedInterface([ instant, dalle, playground], ['InstantüñºÔ∏è','PowerfulüñºÔ∏è', 'Playgroundüñº'])\n",
        "\n",
        "with gr.Blocks() as instant2:\n",
        "    gr.HTML(\"<iframe src='https://kingnish-instant-video.hf.space' width='100%' height='3000px' style='border-radius: 8px;'></iframe>\")\n",
        "\n",
        "with gr.Blocks() as video:\n",
        "    gr.Markdown(\"\"\"More Models are coming\"\"\")\n",
        "    gr.TabbedInterface([ instant2], ['Instantüé•'])"
      ],
      "metadata": {
        "id": "kuCBH8JErBiP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main application block\n",
        "with gr.Blocks(theme=theme, title=\"OpenGPT 4o DEMO\") as demo:\n",
        "    gr.Markdown(\"# OpenGPT 4o\")\n",
        "    gr.TabbedInterface([chat, voice, livechat, image, video], ['üí¨ SuperChat','üó£Ô∏è Voice Chat','üì∏ Live Chat', 'üñºÔ∏è Image Engine', 'üé• Video Engine'])\n",
        "\n",
        "demo.queue(max_size=300)\n",
        "demo.launch()"
      ],
      "metadata": {
        "id": "3iOs75e2rIcF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}